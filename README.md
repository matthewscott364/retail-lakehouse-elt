# ğŸ¬ Retail Lakehouse ELT  
**AWS Â· Databricks Â· dbt Â· Delta Lake**

![AWS](https://img.shields.io/badge/AWS-S3-orange)
![Databricks](https://img.shields.io/badge/Databricks-Lakehouse-red)
![dbt](https://img.shields.io/badge/dbt-Core-green)
![Delta](https://img.shields.io/badge/Delta-Lake-blue)
![Status](https://img.shields.io/badge/Status-Completed-success)

---

## ğŸ“Œ Overview
This project implements an **end-to-end Lakehouse ELT pipeline** using **AWS S3**, **Databricks**, **Unity Catalog**, and **dbt Core**.  
The pipeline follows the **Bronze â†’ Silver â†’ Gold** architecture to ingest raw retail data, apply transformations, enforce data quality, and deliver analytics-ready datasets.

---

## ğŸ§± Architecture Summary

| Layer | Purpose | Technology |
|------|---------|------------|
| ğŸŸ¦ Raw | Immutable source data | AWS S3 |
| ğŸŸ« Bronze | Raw ingestion + metadata | Databricks Delta |
| ğŸŸ© Silver | Cleaning, typing, validation | dbt Core |
| ğŸŸ¨ Gold | Analytics star schema | dbt Core |

---

## ğŸ“ Data Architecture Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¦ AWS S3 (Raw)     â”‚
â”‚ retail_sales.csv   â”‚
â”‚                    â”‚
â”‚ Immutable storage  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ read_files()
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ« Bronze Layer     â”‚
â”‚ Databricks Delta   â”‚
â”‚                    â”‚
â”‚ retail.retail_     â”‚
â”‚ bronze.retail_     â”‚
â”‚ sales              â”‚
â”‚                    â”‚
â”‚ + ingest metadata  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ dbt source()
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ© Silver Layer    â”‚
â”‚ dbt Staging Model  â”‚
â”‚                    â”‚
â”‚ stg_retail_sales   â”‚
â”‚                    â”‚
â”‚ â€¢ Typed columns    â”‚
â”‚ â€¢ Cleaned strings  â”‚
â”‚ â€¢ Data tests       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ dbt ref()
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¨ Gold Layer (Star Schema)  â”‚
â”‚ dbt Analytics Models         â”‚
â”‚                              â”‚
â”‚ â€¢ dim_customer               â”‚
â”‚ â€¢ dim_product_category       â”‚
â”‚ â€¢ fct_sales_transactions     â”‚
â”‚                              â”‚
â”‚ BI-ready analytics tables    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Figure:** End-to-end ELT pipeline using AWS S3 for raw storage, Databricks Delta for Bronze ingestion, dbt for Silver transformations, and Gold analytics models governed by Unity Catalog.

---

## ğŸ›  Tech Stack
- AWS S3  
- Databricks SQL  
- Unity Catalog  
- Delta Lake  
- dbt Core  
- GitHub  

---

## ğŸ“‚ Data Models

### ğŸŸ© Silver (Staging)
- `stg_retail_sales`
  - Standardized column names
  - Typed fields
  - Cleaned strings
  - Validated with dbt tests

### ğŸŸ¨ Gold (Analytics)
- `dim_customer`
- `dim_product_category`
- `fct_sales_transactions`

---

## ğŸ§ª Data Quality
- not_null tests
- unique tests
- Schema enforcement via dbt

---

## â–¶ï¸ How to Run

```bash
dbt run
dbt test
```

---

## ğŸ¯ What This Project Demonstrates
- Cloud-native ELT architecture
- Databricks + Unity Catalog governance
- dbt-driven transformations and testing
- Bronze â†’ Silver â†’ Gold modeling
- Analytics-ready star schema design

---

## ğŸ“ˆ Future Enhancements
- Databricks Job orchestration
- Incremental dbt models
- BI dashboard (Power BI / Tableau)
- CI/CD with GitHub Actions
